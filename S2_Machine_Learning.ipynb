{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63M77nfDF5Y"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBdxXjhPDPJd"
      },
      "source": [
        "Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1v7DU5IDBAV",
        "outputId": "c0fe31f5-559e-410c-b028-fc97cf266c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Color  Color_Encoded\n",
            "0    Red              2\n",
            "1  Green              1\n",
            "2   Blue              0\n",
            "3  Green              1\n",
            "4    Red              2\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {'Color': ['Red', 'Green', 'Blue', 'Green', 'Red']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['Color_Encoded'] = label_encoder.fit_transform(df['Color'])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2dyLp3iDQrC"
      },
      "source": [
        "One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj__UvbiDRwr",
        "outputId": "a6b84c9b-79b9-4cb2-dfcb-54a0296246f6"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# One-hot encoding\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m one_hot_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m encoded_colors \u001b[38;5;241m=\u001b[39m one_hot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColor\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to a DataFrame\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Sample data\n",
        "data = {'Color': ['Red', 'Green', 'Blue', 'Green', 'Red']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# One-hot encoding\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "encoded_colors = one_hot_encoder.fit_transform(df[['Color']])\n",
        "\n",
        "# Convert to a DataFrame\n",
        "encoded_df = pd.DataFrame(encoded_colors, columns=one_hot_encoder.get_feature_names_out(['Color']))\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyFcT4IhDIeD"
      },
      "source": [
        "# Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HKOoBF8DV7C"
      },
      "source": [
        "Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqYvYpn8DIZE",
        "outputId": "245dffbf-44e6-4533-adfb-037db910bbb5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Sample data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m23\u001b[39m],\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncome\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50000\u001b[39m, \u001b[38;5;241m100000\u001b[39m, \u001b[38;5;241m75000\u001b[39m, \u001b[38;5;241m120000\u001b[39m, \u001b[38;5;241m48000\u001b[39m]}\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Standardization\u001b[39;00m\n\u001b[0;32m      9\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample data\n",
        "data = {'Age': [25, 45, 35, 50, 23],\n",
        "        'Income': [50000, 100000, 75000, 120000, 48000]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "df[['Age_Standardized', 'Income_Standardized']] = scaler.fit_transform(df[['Age', 'Income']])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YetqECCXDZ7k"
      },
      "source": [
        "Min-Max Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4aPNlsjDZ1s",
        "outputId": "0b0c4b24-4010-4b8a-c41c-86557976f8e4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Min-Max Normalization\n",
        "min_max_scaler = MinMaxScaler()\n",
        "df[['Age_Normalized', 'Income_Normalized']] = min_max_scaler.fit_transform(df[['Age', 'Income']])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOHMuZEXDKdQ"
      },
      "source": [
        "# Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93GAjpbxFBGz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IincISpFCPZ"
      },
      "outputs": [],
      "source": [
        "# # Generate synthetic data\n",
        "# np.random.seed(42)\n",
        "# X = np.random.rand(100, 1) * 10  # Feature (e.g., size of the house)\n",
        "# y = 2.5 * X**2 + 0.5 * X + np.random.randn(100, 1) * 10  # Quadratic relationship with noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Says8DOOdUCk"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) * 10  # Feature (e.g., size of the house)\n",
        "y = 2.5 * X**2 + 0.5 * X + np.random.randn(100, 1) * 70  # Increased noise level to induce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrGFAPBxFDJQ"
      },
      "outputs": [],
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "dmwZhHp7FEMT",
        "outputId": "abd6558a-259f-446b-b63c-db1b777efe64"
      },
      "outputs": [],
      "source": [
        "# Fit a polynomial regression model with a high degree (overfitting scenario)\n",
        "poly_features = PolynomialFeatures(degree=15)  # High-degree polynomial\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_poly, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsuC5DKZFFMT"
      },
      "outputs": [],
      "source": [
        "# Predictions\n",
        "y_train_pred = model.predict(X_train_poly)\n",
        "y_test_pred = model.predict(X_test_poly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkdgPW0_FF-O"
      },
      "outputs": [],
      "source": [
        "# Calculate R² for training and test sets\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYHLt6iiFGv7",
        "outputId": "cb52e5ad-e986-45e2-8e16-5045ddfd584f"
      },
      "outputs": [],
      "source": [
        "# Print R²\n",
        "print(f\"Training R² (Overfitting): {train_r2:.2f}\")\n",
        "print(f\"Test R² (Overfitting): {test_r2:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "28bYj_kHDKYv",
        "outputId": "feb842f1-dc7c-4abf-8b65-bd1158ad65fb"
      },
      "outputs": [],
      "source": [
        "# 6. Plotting the results to show overfitting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_train, y_train, color='blue', label='Training Data')\n",
        "plt.scatter(X_test, y_test, color='red', label='Test Data')\n",
        "\n",
        "X_plot = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "X_plot_poly = poly_features.transform(X_plot)\n",
        "y_plot = model.predict(X_plot_poly)\n",
        "\n",
        "plt.plot(X_plot, y_plot, color='black', linewidth=2, label='Overfitting Model Prediction')\n",
        "plt.xlabel(\"Feature (e.g., House Size)\")\n",
        "plt.ylabel(\"Target (e.g., House Price)\")\n",
        "plt.title(\"Overfitting in Polynomial Regression (Degree 20)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZmgoQNqcq0l"
      },
      "source": [
        "**Import Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4A9evymcquT"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso, Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hNPfqEict2F"
      },
      "source": [
        "**Apply L1 (Lasso) Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5wsYl4DcsVa",
        "outputId": "56d867f0-794a-406e-9a88-ba79eeab6411"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Apply L1 (Lasso) Regularization\n",
        "lasso_model = Lasso(alpha=0.1)  # The alpha value controls the amount of regularization\n",
        "lasso_model.fit(X_train_poly, y_train)\n",
        "\n",
        "# Predictions using Lasso\n",
        "y_train_pred_lasso = lasso_model.predict(X_train_poly)\n",
        "y_test_pred_lasso = lasso_model.predict(X_test_poly)\n",
        "\n",
        "# Calculate R² score for Lasso\n",
        "train_r2_lasso = r2_score(y_train, y_train_pred_lasso)\n",
        "test_r2_lasso = r2_score(y_test, y_test_pred_lasso)\n",
        "\n",
        "print(f\"Lasso (L1) Training R²: {train_r2_lasso:.2f}\")\n",
        "print(f\"Lasso (L1) Test R²: {test_r2_lasso:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VSUE_WTc2ye"
      },
      "source": [
        "**Apply L2 (Ridge) Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nz4vb5tc2qr",
        "outputId": "f7fa4299-2b54-4381-a95a-e0067cbf069a"
      },
      "outputs": [],
      "source": [
        "# Apply L2 (Ridge) Regularization\n",
        "ridge_model = Ridge(alpha=0.1)  # The alpha value controls the amount of regularization\n",
        "ridge_model.fit(X_train_poly, y_train)\n",
        "\n",
        "# Predictions using Ridge\n",
        "y_train_pred_ridge = ridge_model.predict(X_train_poly)\n",
        "y_test_pred_ridge = ridge_model.predict(X_test_poly)\n",
        "\n",
        "# Calculate R² score for Ridge\n",
        "train_r2_ridge = r2_score(y_train, y_train_pred_ridge)\n",
        "test_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n",
        "\n",
        "print(f\"Ridge (L2) Training R²: {train_r2_ridge:.2f}\")\n",
        "print(f\"Ridge (L2) Test R²: {test_r2_ridge:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X63M77nfDF5Y",
        "CyFcT4IhDIeD",
        "xOHMuZEXDKdQ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
